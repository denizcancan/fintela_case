# Fintela Case Study

A system for processing Turkish fund data, managing investment portfolios, and computing analytical metrics (risk & performance) using data pipelines.

> ğŸ“– **For detailed architecture and design decisions, see [ARCHITECTURE.md](./ARCHITECTURE.md)**

---

# **Quick Start**

## Prerequisites

- Docker and Docker Compose
- Python 3.12+ (if running locally without Docker)
- `uv` package manager ([install here](https://docs.astral.sh/uv/))

## Setup (One Command)

```bash
# Clone the repository
git clone <repository-url>
cd fintela-swe-case

# Make setup script executable (if needed)
chmod +x scripts/setup.sh

# Run setup script (starts Docker, loads data)
./scripts/setup.sh
```

**Note**: If you get a "Permission denied" error, you can also run:
```bash
bash scripts/setup.sh
```

That's it! All services will be running:
- **FastAPI**: http://localhost:8000
- **Dagster**: http://localhost:3000  
- **Dashboard**: http://localhost:5173

## Manual Setup

If you prefer to set up manually:


1. **Start Docker services**:
   ```bash
   docker-compose up -d
   ```

2. **Load fund_labels CSV**:
   ```bash
   uv run python scripts/init_db.py
   ```

3. **Create test portfolios** (optional):
   ```bash
   uv run python create_test_portfolios.py
   ```

---



## Database Tables

All tables are **automatically created** when PostgreSQL starts via Docker Compose:
- `portfolios` - Portfolio definitions
- `portfolio_positions` - Fund positions in portfolios
- `fund_labels` - Fund metadata (loaded from CSV)
- `fund_prices` - Daily fund prices (created by Dagster)
- `instrument_distributions` - Fund instrument distributions (created by Dagster)
- `portfolio_risk_scores` - Portfolio risk calculations
- `fund_performance_metrics` - Fund performance metrics

## Running Locally (Without Docker)

If you have PostgreSQL installed locally:

1. Create database:
   ```bash
   createdb fintela
   ```

2. Run SQL scripts:
   ```bash
   psql -d fintela -f portfolios.sql
   psql -d fintela -f risk_scores.sql
   psql -d fintela -f extra_indexes.sql
   ```

3. Update `.env` with your local PostgreSQL credentials

4. Load CSV:
   ```bash
   uv run python scripts/init_db.py
   ```

5. Start services:
   ```bash
   # FastAPI
   uv run python run_api.py

   # Dagster
   dagster dev
   ```

---
## Design Philosophy & Thinking Process
Ä°lk olarak Dagster dokÃ¼mantasyonunu baÅŸtan sona okudum. Asset yapÄ±sÄ±, dependencies, resources nasÄ±l Ã§alÄ±ÅŸÄ±yor hepsini anlamam gerekti. Sonra READMEâ€™nin kalan kÄ±smÄ±na baktÄ±m, benden tam olarak ne istendiÄŸini netleÅŸtirdim.

Analitik tarafa geÃ§ince, ilk versiyonda portfÃ¶y riskini tamamen volatility (std) Ã¼zerinden hesaplÄ±yordum. Ã‡alÄ±ÅŸÄ±yordu ama iÃ§ime pek sinmedi; biraz yÃ¼zeysel kalÄ±yordu. Sadece gÃ¼nlÃ¼k oynaklÄ±ÄŸa bakmak bana Ã§ok tek boyutlu geldi. Vaktim de olduÄŸu iÃ§in daha mantÄ±klÄ± bir risk modeli kurmak istedim.

Konu Ã¼zerinde araÅŸtÄ±rÄ±nca Markowitz ve CAPM ile karÅŸÄ±laÅŸtÄ±m. CAPM bu proje iÃ§in baya â€œoverkillâ€ duruyordu (benchmark, beta vs. gerektiriyor), o yÃ¼zden onu es geÃ§tim. Ama Markowitzâ€™nin portfÃ¶y yaklaÅŸÄ±mÄ± hoÅŸuma gitti. Komple Markowitz Ã§Ã¶zmek yerine, elimdeki verilere uygun, daha hafif bir versiyon (Markowitz-lite) uygulayabileceÄŸimi gÃ¶rdÃ¼m.

Sonunda risk modelimi ÅŸu dÃ¶rt parÃ§adan oluÅŸturdum:

Kovaryans tabanlÄ± portfÃ¶y volatilitesi (ana risk metriÄŸi)

Herfindahl indeksinden tÃ¼retilmiÅŸ konsantrasyon cezasÄ±

Maksimum drawdown (portfÃ¶yÃ¼n gÃ¶rdÃ¼ÄŸÃ¼ en kÃ¶tÃ¼ dÃ¼ÅŸÃ¼ÅŸ)

Likidite cezasÄ± (market cap + investor countâ€™tan hesapladÄ±ÄŸÄ±m liquidity score)

BunlarÄ±n hepsini normalize edip aÄŸÄ±rlÄ±klandÄ±rarak tek bir risk_score Ã¼rettim. BÃ¶ylece risk artÄ±k sadece oynaklÄ±ktan ibaret olmuyor; portfÃ¶y daÄŸÄ±lÄ±mÄ±, dÃ¼ÅŸÃ¼ÅŸ davranÄ±ÅŸÄ± ve fonlarÄ±n likiditesi de hesaba katÄ±lmÄ±ÅŸ oluyor.

Risk tarafÄ±nÄ± oturttuktan sonra sÄ±ra fon performansÄ±na geldi. Ä°lk yaptÄ±ÄŸÄ±m yaklaÅŸÄ±m Ã§ok basitti:
90 gÃ¼nlÃ¼k cumulative return alÄ±p aynÄ± kategorideki fonlarla kÄ±yaslayÄ±p percentile hesaplÄ±yordum.
Bu Ã§alÄ±ÅŸÄ±yordu ama bazÄ± problemleri vardÄ±:

Sadece getiriyi Ã¶lÃ§mek risk-adjusted deÄŸil (yÃ¼ksek oynak fonlar yanlÄ±ÅŸ ÅŸekilde iyi gÃ¶rÃ¼nÃ¼yordu).

Kategoriler bazen Ã§ok kÃ¼Ã§Ã¼k (3 fon gibi) â†’ percentile gÃ¼venilmez.

Outlier fonlar yÃ¼zÃ¼nden daÄŸÄ±lÄ±m bozuluyordu â†’ yanlÄ±ÅŸ poor-performer alarmÄ± Ã§Ä±kÄ±yordu.

Bunu iyileÅŸtirmek iÃ§in daha mantÄ±klÄ± bir metrik oluÅŸturmaya karar verdim.

AraÅŸtÄ±rma ve Ä°yileÅŸtirme

Markowitz'i risk tarafÄ±nda kullanmÄ±ÅŸtÄ±m, performans tarafÄ±nda da Sharpe Ratio mantÄ±ÄŸÄ±na bakmaya baÅŸladÄ±m. Ama gerÃ§ek Sharpe yapmak iÃ§in risk-free rate vs. gerekiyor. O yÃ¼zden daha basit bir ÅŸey yaptÄ±m:

Yeni Performans Modelim
Her fon iÃ§in:
90 gÃ¼nlÃ¼k total_return (bileÅŸik getiri)

90 gÃ¼nlÃ¼k volatility

sharpe_like = return / volatility

â†’ Yani â€œrisk baÅŸÄ±na getiriyiâ€ hesaplamÄ±ÅŸ oldum.

Sonra peer karÅŸÄ±laÅŸtÄ±rmasÄ± iÃ§in biraz daha akÄ±llÄ± bir mantÄ±k getirdim:

Ã–nce category iÃ§inde kÄ±yasla (yeterince bÃ¼yÃ¼kse)

DeÄŸilse main_category seviyesine Ã§Ä±k

O da olmazsa tÃ¼m fonlarla kÄ±yasla (fallback)

BÃ¶ylece kategori kÃ¼Ã§Ã¼kse saÃ§ma percentile Ã§Ä±kmÄ±yor.

Ek olarak, outlierâ€™larÄ± dÃ¼zeltmek iÃ§in robust bir metrik ekledim:

category iÃ§indeki median

MAD (median absolute deviation)

robust z-score

Poor performer iÅŸaretlemek iÃ§in iki koÅŸulu birlikte kullandÄ±m:

performance_score â‰¤ 0.10 (percentile)

z-score â‰¤ -1.5 (gerÃ§ekten akranlarÄ±ndan belirgin ÅŸekilde kÃ¶tÃ¼)

Bu ikili sayesinde sistem artÄ±k Ã§ok daha â€œtemizâ€ ve spamâ€™siz alert Ã¼retiyor.

SonuÃ§

Yeni model Ã¶nceki modele gÃ¶re daha tutarlÄ±:

YÃ¼ksek oynak ama ÅŸansa iyi getiri yapmÄ±ÅŸ fonlar artÄ±k â€œiyiâ€ gÃ¶rÃ¼nmÃ¼yor.

Ã‡ok dÃ¼ÅŸÃ¼k oynak ama hafif negatif getiri yapan fonlar gereksiz yere kÃ¶tÃ¼ gÃ¶rÃ¼nmÃ¼yor.

Poor performerâ€™lar daha az ama daha â€œgerÃ§ekâ€ oluyor.

Fund performance score artÄ±k sadece getiriyi deÄŸil, risk-adjusted performansÄ± yansÄ±tÄ±yor.
